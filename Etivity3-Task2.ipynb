{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Bartlomiej Mlynarkiewicz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 17241782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Etivity3-Task2.ipynb from the Gitlab repository and the dataset contained therein, create a Naive Bayes Classifier to filter incoming mail for SPAM.\n",
    "\n",
    "The notebook provides a small dataset of previous 'emails' (please note the absence of punctuation which simplifies the coding challenge somewhat). Previous wanted emails are contained in previous_ham. Previous unwanted emails are contained in previous_spam. \n",
    "\n",
    "Write code using Bayes' Rule to determine whether the messages contained in new_emails are HAM or SPAM. Compare the decisions your classifier takes with the label associated with the messages (indicated by the key under which they are stored in the new_emails dictionary. \n",
    "\n",
    "If time permits, add the code required to allow your classifier to learn from the email messages contained in new_emails. Note that this functionality is required to be graded in the Exemplary category. \n",
    "\n",
    "HINTS:\n",
    "\n",
    "1. Use functions to divide up the task in smaller components. It is useful to work through the problem by hand to get a handle on what functions would be useful.\n",
    "2. Choose a suitable threshold of 'spamicity' (or 'spaminess') to distinguish between spam and ham messages in this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Naive Bayes classifier is a probabilistic machine learning model that’s used for classification task. The crux of the classifier is based on the Bayes theorem.\n",
    "\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A|B)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Using Bayes theorem, we can find the probability of A happening, given that B has occurred. Here, B is the evidence and A is the hypothesis. The assumption made here is that the features are independent. That is presence of one particular feature does not affect the other. Hence it is called naive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a `defaultdict` implementation, similar to `defaultdict` provided by the `collections` library. The standard dictionary includes the method setdefault() for retrieving a value and establishing a default if the value does not exist. By contrast, defaultdict lets the caller specify the default(value to be returned) up front when the container is initialized. This is to avoid `KeyError` being thrown if a key doesn't exist within the `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defaultdict(default_type) -> 'DefaultDict':\n",
    "    \"\"\"\n",
    "    Returns a defaultdict object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    default_type\n",
    "        A default type which is used to set the value of item.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    DefaultDict\n",
    "        Returns a an instance of DefaultDict.\n",
    "    \"\"\"\n",
    "    class DefaultDict(dict):\n",
    "        def __getitem__(self, key):\n",
    "            if key not in self:\n",
    "                dict.__setitem__(self, key, default_type())\n",
    "            return dict.__getitem__(self, key)\n",
    "    return DefaultDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize all words within an text, remove fill words and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_fill_words(text):\n",
    "    fill_words = [\n",
    "        \"as\",\n",
    "        \"to\",\n",
    "        \"and\",\n",
    "        \"the\",\n",
    "        \"a\",\n",
    "        \"of\",\n",
    "        \"our\"\n",
    "    ]\n",
    "        \n",
    "    return [word for word in text.split() if word not in fill_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_and_fill_words(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Removes punctuations from the passed in text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        A string\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns a string without punctuations.\n",
    "    \"\"\"\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~,.-'''\n",
    "    clean_text = ''.join(char for char in text if char not in punctuations).lower()\n",
    "    return [word for word in remove_fill_words(clean_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(previous_ham: list[str], previous_spam: list[str]):\n",
    "    \"\"\"\n",
    "    Initializes the required constants required for classification. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    previous_ham: list[str]\n",
    "        A list of previous emails that were catagorised as HAM\n",
    "        \n",
    "    previous_spam: list[str]\n",
    "        A list of previous emails that were catagorised as SPAM\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    spam_word_counts: DefaultDict\n",
    "        Dictionary with frequency of each word in previous spam emails - - Nwi|spam\n",
    "        \n",
    "    ham_word_counts: DefaultDict\n",
    "        Dictionary with frequency of each word in previous ham emails - Nwi|ham\n",
    "        \n",
    "    total_spam_messages: int\n",
    "        The count of previous spam emails\n",
    "        \n",
    "    total_ham_messages: int\n",
    "        The count of previous ham emails\n",
    "        \n",
    "    total_words_in_spam: int \n",
    "        The count of words in previous spam emails - Nspam\n",
    "        \n",
    "    total_words_in_ham: int\n",
    "        The count of words in previous ham emails - Nham\n",
    "    \"\"\"\n",
    "    spam_word_counts = defaultdict(int)\n",
    "    ham_word_counts = defaultdict(int)\n",
    "    \n",
    "    # Count the number of previous spam and ham email\n",
    "    total_spam_messages = len(previous_spam)\n",
    "    total_ham_messages = len(previous_ham)\n",
    "\n",
    "    # Count the number of words in previous spam and ham emails\n",
    "    total_words_in_spam = sum(len(email.split()) for email in previous_spam)\n",
    "    total_words_in_ham = sum(len(email.split()) for email in previous_ham)\n",
    "    \n",
    "    # Count the frequency of each word in previous spam emails\n",
    "    for email in previous_spam:\n",
    "        words = remove_punctuation_and_fill_words(email)\n",
    "        for word in words:\n",
    "            spam_word_counts[word] += 1\n",
    "\n",
    "    # Count the frequency of each word in previous ham emails\n",
    "    for email in previous_ham:\n",
    "        words = remove_punctuation_and_fill_words(email)\n",
    "        for word in words:\n",
    "            ham_word_counts[word] += 1\n",
    "    \n",
    "    return spam_word_counts, ham_word_counts, total_spam_messages, total_ham_messages, total_words_in_spam, total_words_in_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplace smoothing is a smoothing technique that handles the problem of zero probability in Naïve Bayes.\n",
    "\n",
    "$$\n",
    "P(w_i|Spam) = \\frac{N_{wi|Spam} + \\alpha}{N_{Spam} + \\alpha * N_{UniqueWords}}\n",
    "$$\n",
    "\n",
    "- $\\alpha$ represents the smoothing parameter.\n",
    "- $N_{wi|Spam}$ represents the number of times the word occurs in SPAM emails.\n",
    "- $N_{Spam}$represents the count of words in SPAM emails.\n",
    "- $N_{UniqueWords}$ represents the count of unique words in both SPAM and HAM previous emails.\n",
    "\n",
    "$$\n",
    "P(w_i|Ham) = \\frac{N_{wi|Ham} + \\alpha}{N_{Ham} + \\alpha * N_{UniqueWords}}\n",
    "$$\n",
    "\n",
    "- $\\alpha$ represents the smoothing parameter.\n",
    "- $N_{wi|Ham}$ represents the number of times the word occurs in HAM emails.\n",
    "- $N_{Ham}$ represents the count of words in HAM emails.\n",
    "- $N_{UniqueWords}$ represents the count of unique words in both SPAM and HAM previous emails.\n",
    "\n",
    "\n",
    "If a value of $\\alpha$ != 0 is choosen, the probability will no longer be zero even if a word is not present in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example, I use the approach of comparing the $P(Spam|wi)$ is grater than the $P(Ham|wi)$ then the below implementation classified the email as SPAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(email: str, spam_word_counts: 'DefaultDict', ham_word_counts: 'DefaultDict', total_spam_messages: int, total_ham_messages: int, total_words_in_spam: int, total_words_in_ham: int):\n",
    "    \"\"\"\n",
    "    Classified emails SPAM or HAM based on the comparsion between the ham and spam score. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    email: str\n",
    "        A string to be used to classify.\n",
    "        \n",
    "    spam_word_counts: DefaultDict\n",
    "        Dictionary with frequency of each word in previous spam emails - - Nwi|spam\n",
    "        \n",
    "    ham_word_counts: DefaultDict\n",
    "        Dictionary with frequency of each word in previous ham emails - Nwi|ham\n",
    "        \n",
    "    total_spam_messages: int\n",
    "        The count of previous spam emails\n",
    "        \n",
    "    total_ham_messages: int\n",
    "        The count of previous ham emails\n",
    "        \n",
    "    total_words_in_spam: int \n",
    "        The count of words in previous spam emails - Nspam\n",
    "        \n",
    "    total_words_in_ham: int\n",
    "        The count of words in previous ham emails - Nham\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    spamminess_score: float\n",
    "        The ratio of the spam score to the ham score.\n",
    "        \n",
    "    prediction: str\n",
    "        The email classification based on the ratio of the spam score to the ham score.\n",
    "    \"\"\"\n",
    "    # Tokenize email and lower case each token\n",
    "    email_tokenized = remove_punctuation_and_fill_words(email)\n",
    "    \n",
    "    # Laplace smoothing\n",
    "    alpha = 1\n",
    "\n",
    "    # Calculate P(S) -> P(Spam)\n",
    "    spam_score = total_spam_messages / (total_spam_messages + total_ham_messages)\n",
    "    # Calculate P(¬S) -> P(Ham)\n",
    "    ham_score = total_ham_messages / (total_spam_messages + total_ham_messages)\n",
    "    \n",
    "    # Count of unique words in both Spam and Ham\n",
    "    no_of_uniqe_words = len(set().union(spam_word_counts.keys(), ham_word_counts.keys()))\n",
    "\n",
    "    for word in email_tokenized:\n",
    "        # Calculate the conditional probabilities P(w_i|Spam) and P(w_i|Ham)\n",
    "        prob_word_given_spam = (spam_word_counts[word] + alpha) / (total_words_in_spam + (alpha*no_of_uniqe_words))\n",
    "        prob_word_given_ham = (ham_word_counts[word] + alpha) / (total_words_in_ham + (alpha*no_of_uniqe_words))\n",
    "        \n",
    "        # Update the spam and ham scores by multiplying them with the calculated conditional probabilities for each word in the email.\n",
    "        spam_score *= prob_word_given_spam\n",
    "        ham_score *= prob_word_given_ham\n",
    "    \n",
    "    # The spamminess score is calculated as the ratio of the spam score to the ham score.\n",
    "    spamminess_score = spam_score / ham_score\n",
    "    \n",
    "    # Classify SPAM if spam_score > ham_score\n",
    "    prediction = 'spam' if spam_score > ham_score else 'ham' \n",
    "    \n",
    "    return prediction, spamminess_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pritty_print(lst, msg):\n",
    "    print(f\"\\033[1m{msg}\\033[0m\\n\")\n",
    "    for index, obj in enumerate(lst):\n",
    "        print(f\"{index+1}.\\033[1m{'Email:':<40}\\033[0m {obj['email'] if 'email' in obj else obj}\")\n",
    "        if 'spamminess_score' in obj:\n",
    "            print(f\"{index+1}.\\033[1m{'Spaminess Score:':<40}\\033[0m {obj['spamminess_score']}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the predicted values with the actual values to measure how good our spam filter is with classifying new emails. \n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{no. of correctly classified emails}}{\\text{total number of classified emails}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(classified_emails: dict, new_emails: dict):\n",
    "    total = sum(len(new_emails[key]) for key in list(new_emails.keys()))\n",
    "    \n",
    "    spam_count = len(list(set(new_emails['spam']).intersection(set(email['email'] for email in classified_emails['spam']))))\n",
    "    ham_count = len(list(set(new_emails['ham']).intersection(set(email['email'] for email in classified_emails['ham']))))\n",
    "    \n",
    "    print('Correct:', spam_count + ham_count)\n",
    "    print('Incorrect:', total - (spam_count+ham_count))\n",
    "    print('Accuracy:', (spam_count+ham_count)/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the classifier to predict whether new emails are SPAM or HAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_word_counts, ham_word_counts, total_spam_messages, total_ham_messages, total_words_in_spam, total_words_in_ham = train_naive_bayes(previous_ham, previous_spam)\n",
    "    \n",
    "classified_emails = {'spam': [], 'ham': []}\n",
    "spam_word_score = defaultdict(int)\n",
    "ham_word_score = defaultdict(int)\n",
    "\n",
    "for label, emails in new_emails.items():\n",
    "    for email in emails:\n",
    "        prediction, spamminess_score = predict_naive_bayes(email, spam_word_counts, ham_word_counts, total_spam_messages, total_ham_messages, total_words_in_spam, total_words_in_ham)\n",
    "        classified_emails[prediction].append({\"email\": email, \"spamminess_score\": spamminess_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrevious SPAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m send us your password\n",
      "2.\u001b[1mEmail:                                  \u001b[0m review our website\n",
      "3.\u001b[1mEmail:                                  \u001b[0m send your password\n",
      "4.\u001b[1mEmail:                                  \u001b[0m send us your account\n",
      "\n",
      "\u001b[1mPrevious HAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m Your activity report\n",
      "2.\u001b[1mEmail:                                  \u001b[0m benefits physical activity\n",
      "3.\u001b[1mEmail:                                  \u001b[0m the importance vows\n",
      "\n",
      "\u001b[1mActual SPAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m renew your password\n",
      "2.\u001b[1mEmail:                                  \u001b[0m renew your vows\n",
      "\n",
      "\u001b[1mActual HAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m benefits of our account\n",
      "2.\u001b[1mEmail:                                  \u001b[0m the importance of physical activity\n",
      "\n",
      "\u001b[1mBayes Classified SPAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m renew your password\n",
      "1.\u001b[1mSpaminess Score:                        \u001b[0m 4.327795559619975\n",
      "\n",
      "\n",
      "\u001b[1mBayes Classified HAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m renew your vows\n",
      "1.\u001b[1mSpaminess Score:                        \u001b[0m 0.7390063168124392\n",
      "\n",
      "2.\u001b[1mEmail:                                  \u001b[0m benefits of our account\n",
      "2.\u001b[1mSpaminess Score:                        \u001b[0m 0.8996598639455782\n",
      "\n",
      "3.\u001b[1mEmail:                                  \u001b[0m the importance of physical activity\n",
      "3.\u001b[1mSpaminess Score:                        \u001b[0m 0.06158385973436994\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pritty_print(previous_spam, \"Previous SPAM\")\n",
    "pritty_print(previous_ham, \"Previous HAM\")\n",
    "\n",
    "pritty_print(new_emails['spam'], \"Actual SPAM\")\n",
    "pritty_print(new_emails['ham'], \"Actual HAM\")\n",
    "\n",
    "pritty_print(classified_emails['spam'], \"Bayes Classified SPAM\")\n",
    "pritty_print(classified_emails['ham'], \"Bayes Classified HAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3\n",
      "Incorrect: 1\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(classified_emails, new_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated email subject lines to increase the training set to improve the models accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_spa_samples = new_emails['spam'] +  [\n",
    "     \"Exciting Product Launch: Don't Miss Our Latest Gadgets!\",\n",
    "    \"Join Our Webinar: Digital Marketing Strategies for Success\",\n",
    "    \"Adventure Retreats: Explore Remote Wilderness with Us\",\n",
    "    \"Exclusive Sale: Get 40% Off on Latest Fashion Trends\",\n",
    "    \"Mastering Time Management: Boost Your Productivity\",\n",
    "    \"Culinary Journey: Explore International Cuisine with Us\",\n",
    "    \"Career Advancement: Strategies for Success in the Workplace\",\n",
    "    \"Sustainable Living: Eco-Friendly Tips for a Greener Future\",\n",
    "    \"Art & Culture Festival: Celebrating Diversity in Our City\",\n",
    "    \"Discover Hidden Treasures: Antique Collecting Insights\",\n",
    "    \"Space Exploration News: Unprecedented Discoveries\",\n",
    "    \"Smart Living: Transform Your Home with Technology\",\n",
    "    \"Hiking Adventures: Conquer Majestic Peaks and Trails\",\n",
    "    \"Women in Leadership: Empowering Female Entrepreneurs\",\n",
    "    \"Historical Mysteries: Explore Ancient Civilizations\",\n",
    "    \"eSports Phenomenon: Dive into Competitive Gaming\",\n",
    "    \"Photography Mastery: Learn from the Pros\",\n",
    "    \"Financial Planning: Tips for a Secure Future\",\n",
    "    \"Mindfulness & Meditation: Find Inner Peace and Resilience\",\n",
    "    \"Fashion Evolution: Styles through the Decades\"\n",
    "]\n",
    "\n",
    "extra_ham_samples = new_emails['ham'] + [\n",
    "    \"Explore the Secrets of Ancient Egypt: Unearth Mysteries of the Pharaohs, Pyramids, and Hieroglyphs in Our Archaeological Expedition\",\n",
    "    \"Revolutionize Your Home Office: Discover Ergonomic Furniture, High-Tech Gadgets, and Office Equipment for Ultimate Comfort and Productivity\",\n",
    "    \"Journey to the Stars: Join Our Astronaut Training Program and Experience the Rigorous Preparations for Space Exploration\",\n",
    "    \"Immerse Yourself in World Literature: Our Acclaimed Book Club Delves Deep into Timeless Classics and Engages in Thoughtful Literary Discussions\",\n",
    "    \"Embark on an Epic Culinary Adventure: Experience the Art of Cooking with Michelin-Starred Chefs and Master the Secrets of Gourmet Cuisine\",\n",
    "    \"Unleash Your Inner Explorer: Join Our Adventure Club and Traverse the Most Remote and Breathtaking Corners of the Globe\",\n",
    "    \"Redefine Sustainable Living: Eco-Friendly Practices and Green Innovations for a More Environmentally Conscious Lifestyle\",\n",
    "    \"Elevate Your Career: Uncover the Secrets of Effective Leadership and Team Management in Our Comprehensive Leadership Development Program\",\n",
    "    \"Escape to Tropical Paradise: Our Luxury Island Retreat in the Maldives Offers Pristine Beaches, Sunshine, and Overwater Bungalows\",\n",
    "    \"Transform Your Backyard into a Serene Oasis: Explore Our Luxurious Outdoor Furniture and Garden Decor Made from Sustainable Materials\",\n",
    "    \"Dive Deep into Ocean Conservation: Join Our Marine Biology Expedition for Hands-On Research, Diving, and Wildlife Encounters\",\n",
    "    \"Experience the Power of Giving: Our Philanthropy Symposium Focuses on Transforming Lives and Making a Positive Impact in Your Community\",\n",
    "    \"A Journey Through Ancient History: Explore Mythology, Civilizations, and Archaeological Sites That Shaped Our World\",\n",
    "    \"Discover the Future of Transportation: Get Behind the Wheel of Electric Vehicles with Advanced Autonomous Features and Eco-Friendly Mobility Solutions\",\n",
    "    \"Charting New Horizons in Medicine: Explore the Latest Healthcare Innovations and Breakthroughs with Insights from Medical Professionals\",\n",
    "    \"Unleash Your Creativity: Join Our Workshop Series with Renowned Artists and Innovators to Explore New Perspectives in Art and Design\",\n",
    "    \"Elevate Your Financial Literacy: Enroll in Our Personal Finance Course Covering Budgeting, Investing, Retirement Planning, and Wealth Management\",\n",
    "    \"Witness the Majesty of Opera: Our Exclusive Opera Tour Takes You to Prestigious Venues in Europe, Where You'll Meet Opera Stars and Enjoy World-Class Performances\",\n",
    "    \"Savor the Flavors of the World: Join Our International Food Festival and Delight in Culinary Delights from Around the Globe\",\n",
    "    \"The Future of Education: Explore Innovations in Learning and Teaching in Our Symposium with Expert Educators and Visionaries\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_word_counts, ham_word_counts, total_spam_messages, total_ham_messages, total_words_in_spam, total_words_in_ham = train_naive_bayes(previous_ham + extra_ham_samples, previous_spam + extra_spa_samples)\n",
    "    \n",
    "classified_emails = {'spam': [], 'ham': []}\n",
    "spam_word_score = defaultdict(int)\n",
    "ham_word_score = defaultdict(int)\n",
    "\n",
    "for label, emails in new_emails.items():\n",
    "    for email in emails:\n",
    "        prediction, spamminess_score = predict_naive_bayes(email, spam_word_counts, ham_word_counts, total_spam_messages, total_ham_messages, total_words_in_spam, total_words_in_ham)\n",
    "        classified_emails[prediction].append({\"email\": email, \"spamminess_score\": spamminess_score}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrevious SPAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m send us your password\n",
      "2.\u001b[1mEmail:                                  \u001b[0m review our website\n",
      "3.\u001b[1mEmail:                                  \u001b[0m send your password\n",
      "4.\u001b[1mEmail:                                  \u001b[0m send us your account\n",
      "\n",
      "\u001b[1mPrevious HAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m Your activity report\n",
      "2.\u001b[1mEmail:                                  \u001b[0m benefits physical activity\n",
      "3.\u001b[1mEmail:                                  \u001b[0m the importance vows\n",
      "\n",
      "\u001b[1mActual SPAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m renew your password\n",
      "2.\u001b[1mEmail:                                  \u001b[0m renew your vows\n",
      "\n",
      "\u001b[1mActual HAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m benefits of our account\n",
      "2.\u001b[1mEmail:                                  \u001b[0m the importance of physical activity\n",
      "\n",
      "\u001b[1mBayes Classified SPAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m renew your password\n",
      "1.\u001b[1mSpaminess Score:                        \u001b[0m 37.68631500234906\n",
      "\n",
      "2.\u001b[1mEmail:                                  \u001b[0m renew your vows\n",
      "2.\u001b[1mSpaminess Score:                        \u001b[0m 9.421578750587265\n",
      "\n",
      "\n",
      "\u001b[1mBayes Classified HAM\u001b[0m\n",
      "\n",
      "1.\u001b[1mEmail:                                  \u001b[0m benefits of our account\n",
      "1.\u001b[1mSpaminess Score:                        \u001b[0m 0.7834173014953386\n",
      "\n",
      "2.\u001b[1mEmail:                                  \u001b[0m the importance of physical activity\n",
      "2.\u001b[1mSpaminess Score:                        \u001b[0m 0.09814144531861736\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pritty_print(previous_spam, \"Previous SPAM\")\n",
    "pritty_print(previous_ham, \"Previous HAM\")\n",
    "\n",
    "pritty_print(new_emails['spam'], \"Actual SPAM\")\n",
    "pritty_print(new_emails['ham'], \"Actual HAM\")\n",
    "\n",
    "pritty_print(classified_emails['spam'], \"Bayes Classified SPAM\")\n",
    "pritty_print(classified_emails['ham'], \"Bayes Classified HAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4\n",
      "Incorrect: 0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(classified_emails, new_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
