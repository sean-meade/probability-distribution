{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Vaclav Krol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 23307102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes algorithm\n",
    "\n",
    "In a nutshell:\n",
    "\n",
    "1. Iterate over the labelled spam emails and, for each word w in the entire training set, count how many\n",
    "of the spam emails contain w. Compute\n",
    "$$P(w | S) = \\frac{|spam\\, emails\\, containing\\, w|+1)} {|spam\\, emails|\\, +\\, 2} $$\n",
    "<br>\n",
    "2. Compute P(w | H) the same way for ham emails.\n",
    "<br><br>\n",
    "3. Compute the total probability of spam emails based on hand-labelled data\n",
    "$$ P(S) = \\frac{|spam\\, emails|} {(|spam\\, emails|\\, +\\, |ham emails|)}$$\n",
    "<br>\n",
    "4. Compute the total probability of ham emails based on hand-labelled data\n",
    "$$ P(H) = \\frac{|ham\\, emails|} {(|spam\\, emails|\\, +\\, |ham emails|)}$$\n",
    "<br>\n",
    "5. Given a set of unlabelled test emails, iterate over each:\n",
    "- Create a set {x1, . . . , xn} of the distinct words in the email. Ignore the words that you haven’t\n",
    "seen in the labelled training data.\n",
    "- Compute<br>\n",
    "$$P(S | x1, . . . , xn) ≈ \\frac{P(S) \\prod_{i=1}^n P(x_i | S)}{P(S) \\prod_{i=1}^n P(x_i | S)\\quad + \\quad P(H) \\prod_{i=1}^n P(x_i | H) }\\$$\n",
    "<br>\n",
    "- If P(S | x1, . . . , xn) > 0.5, output “spam”, else output “ham”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, let's set a couple of constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants\n",
    "\n",
    "# Adding \"1\" to numerator when multiplying probabilities, to avoid the zero result for unknown words\n",
    "P_ADD_TO_NUMERATOR = 1\n",
    "\n",
    "# We are adding 2 to the denominator because we have 2 classes - SPAM and HAM\n",
    "# (you either love or hate Monty Python - I am in the first group!)\n",
    "P_ADD_TO_DENOMINATOR = 2\n",
    "\n",
    "# Key name for new unlabelled spam emails\n",
    "SPAM_DICT_KEY = 'spam'\n",
    "\n",
    "# Key name for new unlabelled ham emails\n",
    "HAM_DICT_KEY = 'ham'\n",
    "\n",
    "# Not important words that should not be checked for SPAM\n",
    "UNIMPORTANT_WORDS = ['us', 'the', 'of', 'your']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial probabilities for computations:<br>\n",
    "We are given a set of 7 emails in total, 4 of which are SPAM and 3 of which are HAM.<br>\n",
    "That means:<br>\n",
    "P(S) = 4/7<br>\n",
    "P(H) = 3/7\n",
    "\n",
    "But let's define universal functions to get these probabilities based on the input lists of emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pr_S_Total() -> float:\n",
    "    '''\n",
    "    Returns the general probability of any email being spam based on evidence.\n",
    "    \n",
    "    ::Returns\n",
    "    A float value representing the SPAM probability based on evidence (total number of checked spams and hams)\n",
    "    '''\n",
    "    \n",
    "    # General probability of spam\n",
    "    Pr_S = len(previous_spam) / ( len(previous_spam) + len(previous_ham) )\n",
    "    \n",
    "    return (Pr_S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pr_H_Total() -> float:\n",
    "    '''\n",
    "    Returns the general probability of any email being HAM based on evidence.\n",
    "    \n",
    "    ::Returns\n",
    "    A float value representing the HAM probability based on evidence (total number of checked spams and hams)\n",
    "    '''\n",
    "    \n",
    "    # General probability of ham\n",
    "    Pr_H = len(previous_ham) / ( len(previous_spam) + len(previous_ham) )\n",
    "    \n",
    "    return (Pr_H)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words_in_emails(email_list: list[str]) -> list[str]:\n",
    "    '''\n",
    "    Returns all unique words from the input list of strings\n",
    "    Case insensitive\n",
    "    \n",
    "    ::Params\n",
    "    email_list: list[str] (for example: ['Your activity report','Your benefits activity'] )\n",
    "    It is assumed that words in strings are split by space\n",
    "\n",
    "    ::Returns\n",
    "    A list of unique words from the given list of strings\n",
    "    An example for the input above: ['Your', 'activity', 'report', 'benefits']\n",
    "    '''\n",
    "\n",
    "    # Getting all words\n",
    "    words_all = [item.lower() for sublist in email_list for item in sublist.split()]\n",
    "\n",
    "    # Remove duplicities\n",
    "    words_unique = list(set(words_all))\n",
    "\n",
    "    return (words_unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emails_with_word(email_list: list[str], word: str) -> list[str]:\n",
    "    '''\n",
    "    Returns all \"emails\" (strings) from the input list that contain the input word\n",
    "    Case insensitive\n",
    "    \n",
    "    ::Params\n",
    "    email_list: list[str] (for example: ['Your activity report','Your benefits activity'] )\n",
    "    It is assumed that words in strings are split by space\n",
    "    \n",
    "    ::Returns\n",
    "    A subset of strings from the input list that contain the given word\n",
    "    An example for the input above and word \"report\": ['Your activity report']\n",
    "    '''\n",
    "    \n",
    "    out_list = list()\n",
    "    for email in email_list:\n",
    "        if word.lower() in email.lower():\n",
    "            out_list.append(email)\n",
    "            \n",
    "    return (out_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_of_emails_with_word(email_list: list[list[str]], word: str) -> list[str]:\n",
    "    '''\n",
    "    Returns the number of emails (strings) from the input list that contain the input word\n",
    "    \n",
    "    ::Params\n",
    "    email_list: list[str] (for example: ['Your activity report','Your benefits activity'] )\n",
    "    It is assumed that words in strings are split by space\n",
    "    \n",
    "    ::Returns\n",
    "    A number of strings from the input list that contain the given word\n",
    "    An example for the input above and word \"Your\": 2\n",
    "    '''\n",
    "\n",
    "    out_nb = 0\n",
    "    for email in email_list:\n",
    "        if word in email:\n",
    "            out_nb += 1\n",
    "            \n",
    "    return (out_nb)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_word_in_emails(word_list: list[str], email_list: list[str]) -> dict():\n",
    "    '''\n",
    "    Returns a dictionary:\n",
    "       keys: all words from the word_list\n",
    "       values: calculated probability of the word in the list of emails (strings)\n",
    "       \n",
    "    ::Params\n",
    "    email_list: list[str] (for example: ['Your activity report','Your benefits activity'] )\n",
    "    It is assumed that words in strings are split by space\n",
    "    \n",
    "    ::Returns\n",
    "    Returns a dictionary {word(str): probability(float) }, where:\n",
    "       keys: all words from the word_list\n",
    "       values: calculated probability of the word in the list of emails (strings)\n",
    "    '''\n",
    "    \n",
    "    # Get the total number of emails in the list\n",
    "    nb_all_emails = len(email_list)\n",
    "\n",
    "    # Creating a dictionary with words as keys and probability as values\n",
    "    dict_probability = {}\n",
    "    \n",
    "    for word in word_list:\n",
    "        nb_emails_w_word = nb_of_emails_with_word(email_list, word)\n",
    "        probability = (nb_emails_w_word + P_ADD_TO_NUMERATOR) / (nb_all_emails + P_ADD_TO_DENOMINATOR)\n",
    "        dict_probability[word.lower()] = probability\n",
    "\n",
    "    return(dict_probability)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(sentence: str, words_to_remove: list[str]) -> str:\n",
    "    '''\n",
    "    Removes words from a sentence and returns that sentence without them\n",
    "    '''\n",
    "    # Split the sentence into a list of words\n",
    "    words = sentence.split()\n",
    "\n",
    "    # Create a new list of words excluding the ones to be removed\n",
    "    new_words = [word for word in words if word not in words_to_remove]\n",
    "\n",
    "    # Join the words back into a sentence\n",
    "    new_sentence = ' '.join(new_words)\n",
    "\n",
    "    return new_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of Naive Bayes probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bayes_prob(email: str, dict_label_spamicity: dict(), dict_label_hamicity: dict()) -> float:\n",
    "    '''\n",
    "    Calculates the probability of the input email being a spam.\n",
    "    The function is based on the Bayes Naive Theorem.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Nb of samples for SPAM and HAM\n",
    "    nb_of_label_emails_spam = len(previous_spam)\n",
    "    nb_of_label_emails_ham = len(previous_ham)\n",
    "    \n",
    "    # Overall probabilities of any email being SPAM or HAM\n",
    "    Pr_S = Pr_S_Total()\n",
    "    Pr_H = Pr_H_Total()\n",
    "    \n",
    "    probabilities = []\n",
    "    \n",
    "    email_word_list = email.split()\n",
    "    \n",
    "    # Calculating the probability for each word and adding into a list - they get multiplied at the end \n",
    "    for word in email_word_list:\n",
    "\n",
    "        # Computing Pr_wS - word in SPAM\n",
    "        if word in dict_label_spamicity:\n",
    "            Pr_wS = dict_label_spamicity[word]\n",
    "        else:\n",
    "            # Smoothing for word not seen in spam training data, but seen in ham training \n",
    "            Pr_wS = 1 / (nb_of_label_emails_spam + 2)\n",
    "\n",
    "        # Computing Pr_wH - word in HAM\n",
    "        if word in dict_label_hamicity:\n",
    "            Pr_wH = dict_label_hamicity[word]\n",
    "        else:\n",
    "            # Apply smoothing for word not seen in ham training data, but seen in spam training\n",
    "            Pr_wH = 1 / (nb_of_label_emails_ham + 2)\n",
    "\n",
    "        # The Bayes formula for current word\n",
    "        Pr_bayes_word_spam = (Pr_wS * Pr_S) / ((Pr_wS * Pr_S) + (Pr_wH * Pr_H))\n",
    "\n",
    "        # Adding the word probability into the list \n",
    "        probabilities.append(Pr_bayes_word_spam)\n",
    "\n",
    "        \n",
    "    # Calculating the final probability\n",
    "    Pr_final_bayes = 1\n",
    "    for i in probabilities: \n",
    "         Pr_final_bayes = Pr_final_bayes * i  \n",
    "\n",
    "    return(Pr_final_bayes)\n",
    "            \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "------- Probability for expected SPAM emails -------- \n",
      "\n",
      "Probability that the following email is SPAM: renew your password \n",
      "76.92 %\n",
      "\n",
      "Probability that the following email is SPAM: renew your vows \n",
      "35.71 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "------- Probability for expected HAM emails -------- \n",
      "\n",
      "Probability that the following email is SPAM: benefits of our account \n",
      "20.87 %\n",
      "\n",
      "Probability that the following email is SPAM: the importance of physical activity \n",
      "3.45 %\n"
     ]
    }
   ],
   "source": [
    "# Let's get all unique words included in the SPAM emails\n",
    "unique_words_label_spam = unique_words_in_emails(previous_spam)\n",
    "\n",
    "# Calculation of \"Spamicity\" for each unique word\n",
    "# by taking the total number of emails that have already been deemed as spam\n",
    "dict_label_spamicity = probability_word_in_emails(unique_words_spam, previous_spam)\n",
    "\n",
    "# Let's do the same for HAM - unique words and calculation of \"Hamicity\" for each word\n",
    "unique_words_label_ham = unique_words_in_emails(previous_ham)\n",
    "dict_label_hamicity = probability_word_in_emails(unique_words_ham, previous_ham)\n",
    "\n",
    "# Given a set of un-labelled emails, iterate over each and create a list of distinct words\n",
    "# Let's get distinct words for unlabelled spam and ham emails\n",
    "list_unlabel_spam = new_emails[SPAM_DICT_KEY]\n",
    "unique_words_unlabel_spam = unique_words_in_emails(list_unlabel_spam)\n",
    "\n",
    "list_unlabel_ham = new_emails[HAM_DICT_KEY]\n",
    "unique_words_unlabel_ham = unique_words_in_emails(list_unlabel_ham)\n",
    "\n",
    "# Let's find the words from our new unlabelled emails that we have not seen in the previous data\n",
    "# Unknown unique words HAM\n",
    "unique_unknown_words_unlabel_ham = [word for word in unique_words_unlabel_ham if word not in (unique_words_label_spam + unique_words_label_ham)]\n",
    "\n",
    "# Unknown unique words SPAM\n",
    "unique_unknown_words_unlabel_spam = [word for word in unique_words_unlabel_spam if word not in (unique_words_label_spam + unique_words_label_ham)]\n",
    "\n",
    "\n",
    "# Checking new SPAM emails and their probability\n",
    "print(80*'-')\n",
    "print('------- Probability for expected SPAM emails -------- ')\n",
    "for new_email in new_emails[SPAM_DICT_KEY]:\n",
    "    # print(80*'-')\n",
    "    print(f'\\nProbability that the following email is SPAM: {new_email} ')\n",
    "    # Let's remove unknown and unimportant words from the email\n",
    "    new_email_wout_unknowns = remove_words(remove_words(new_email, unique_unknown_words_unlabel_spam),UNIMPORTANT_WORDS)\n",
    "    all_word_probs = calc_bayes_prob(new_email_wout_unknowns, dict_label_spamicity, dict_label_hamicity)\n",
    "    print(\"{:.2f}\".format(all_word_probs * 100.0) + \" %\")\n",
    "\n",
    "\n",
    "# Checking new HAM emails and their probability\n",
    "print('\\n')\n",
    "print(80*'-')\n",
    "print('------- Probability for expected HAM emails -------- ')\n",
    "for new_email in new_emails[HAM_DICT_KEY]:\n",
    "    print(f'\\nProbability that the following email is SPAM: {new_email} ')\n",
    "    # Let's remove unknown and unimportant words from the email\n",
    "    new_email_wout_unknowns = remove_words(remove_words(new_email, unique_unknown_words_unlabel_ham),UNIMPORTANT_WORDS)\n",
    "    all_word_probs = calc_bayes_prob(new_email_wout_unknowns, dict_label_spamicity, dict_label_hamicity)\n",
    "    print(\"{:.2f}\".format(all_word_probs * 100.0) + \" %\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write you reflection in below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
