{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Phil Clarke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 23291567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_spam = []\n",
    "\n",
    "for sentence in previous_spam:\n",
    "    sentence_as_list = sentence.split()\n",
    "    for word in sentence_as_list:\n",
    "        vocab_words_spam.append(word)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['send', 'us', 'your', 'password', 'review', 'our', 'website', 'send', 'your', 'password', 'send', 'us', 'your', 'account']\n",
      "['send', 'us', 'your', 'password', 'review', 'our', 'website', 'account']\n"
     ]
    }
   ],
   "source": [
    "print(vocab_words_spam)\n",
    "vocab_unique_words_spam = list(dict.fromkeys(vocab_words_spam))\n",
    "print(vocab_unique_words_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_ham = []\n",
    "\n",
    "for sentence in previous_ham:\n",
    "    sentence_as_list = sentence.split()\n",
    "    for word in sentence_as_list:\n",
    "        vocab_words_ham.append(word)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Your', 'activity', 'report', 'benefits', 'physical', 'activity', 'the', 'importance', 'vows']\n",
      "['Your', 'activity', 'report', 'benefits', 'physical', 'the', 'importance', 'vows']\n"
     ]
    }
   ],
   "source": [
    "print(vocab_words_ham)\n",
    "vocab_unique_words_ham = list(dict.fromkeys(vocab_words_ham))\n",
    "print(vocab_unique_words_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS #I have removed the stop words here\n",
    "\n",
    "stop_words = set(map(str.lower, ENGLISH_STOP_WORDS))\n",
    "filtered_words_SPAM = [word for word in vocab_unique_words_spam if word.lower() not in stop_words]\n",
    "filtered_words_HAM = [word for word in vocab_unique_words_ham if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['send', 'password', 'review', 'website', 'account']\n",
      "['activity', 'report', 'benefits', 'physical', 'importance', 'vows']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_words_SPAM)\n",
    "print(filtered_words_HAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send: send us your password\n",
      "send: send your password\n",
      "send: send us your account\n",
      "Number of spam emails with the word send: 3\n",
      "Spamicity of the word 'send': 0.6666666666666666 \n",
      "\n",
      "password: send us your password\n",
      "password: send your password\n",
      "Number of spam emails with the word password: 2\n",
      "Spamicity of the word 'password': 0.5 \n",
      "\n",
      "review: review our website\n",
      "Number of spam emails with the word review: 1\n",
      "Spamicity of the word 'review': 0.3333333333333333 \n",
      "\n",
      "website: review our website\n",
      "Number of spam emails with the word website: 1\n",
      "Spamicity of the word 'website': 0.3333333333333333 \n",
      "\n",
      "account: send us your account\n",
      "Number of spam emails with the word account: 1\n",
      "Spamicity of the word 'account': 0.3333333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_spamicity = {}\n",
    "for w in filtered_words_SPAM:\n",
    "    emails_with_w = 0     # counter\n",
    "    for sentence in previous_spam:\n",
    "        if w in sentence:\n",
    "            print(w+\":\", sentence)\n",
    "            emails_with_w+=1\n",
    "            \n",
    "    print(f\"Number of spam emails with the word {w}: {emails_with_w}\")\n",
    "    total_spam = len(previous_spam)\n",
    "    spamicity = (emails_with_w+1)/(total_spam+2)\n",
    "    print(f\"Spamicity of the word '{w}': {spamicity} \\n\")\n",
    "    dict_spamicity[w.lower()] = spamicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity: Your activity report\n",
      "activity: benefits physical activity\n",
      "Number of spam emails with the word activity: 2\n",
      "hamicity of the word 'activity': 0.6 \n",
      "\n",
      "report: Your activity report\n",
      "Number of spam emails with the word report: 1\n",
      "hamicity of the word 'report': 0.4 \n",
      "\n",
      "benefits: benefits physical activity\n",
      "Number of spam emails with the word benefits: 1\n",
      "hamicity of the word 'benefits': 0.4 \n",
      "\n",
      "physical: benefits physical activity\n",
      "Number of spam emails with the word physical: 1\n",
      "hamicity of the word 'physical': 0.4 \n",
      "\n",
      "importance: the importance vows\n",
      "Number of spam emails with the word importance: 1\n",
      "hamicity of the word 'importance': 0.4 \n",
      "\n",
      "vows: the importance vows\n",
      "Number of spam emails with the word vows: 1\n",
      "hamicity of the word 'vows': 0.4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_hamicity = {}\n",
    "for w in filtered_words_HAM:\n",
    "    emails_with_w = 0     # counter\n",
    "    for sentence in previous_ham:\n",
    "        if w in sentence:\n",
    "            print(w+\":\", sentence)\n",
    "            emails_with_w+=1\n",
    "            \n",
    "    print(f\"Number of spam emails with the word {w}: {emails_with_w}\")\n",
    "    total_ham = len(previous_ham)\n",
    "    hamicity = (emails_with_w+1)/(total_ham+2)\n",
    "    print(f\"hamicity of the word '{w}': {hamicity} \\n\")\n",
    "    dict_hamicity[w.lower()] = hamicity       \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Ham {'activity': 0.6, 'report': 0.4, 'benefits': 0.4, 'physical': 0.4, 'importance': 0.4, 'vows': 0.4}\n",
      "Dictionary Spam {'send': 0.6666666666666666, 'password': 0.5, 'review': 0.3333333333333333, 'website': 0.3333333333333333, 'account': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary Ham\", dict_hamicity)\n",
    "#\n",
    "print(\"Dictionary Spam\", dict_spamicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "prob_spam = len(previous_spam) / (len(previous_spam)+(len(previous_ham)))\n",
    "print(prob_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "prob_ham = len(previous_ham) / (len(previous_spam)+(len(previous_ham)))\n",
    "print(prob_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_spam = [\n",
    "    'send us your password',\n",
    "    'transmit us your password',\n",
    "    'transmit us your password',\n",
    "    'submit us your password',\n",
    "    'send us your password',\n",
    "    'critique our website',\n",
    "    'followup our website',\n",
    "    'inspection our website',\n",
    "    'review our website',\n",
    "    'review our website',\n",
    "    'send your password',\n",
    "    'transmit your password',\n",
    "    'transmit your password',\n",
    "    'submit your password',\n",
    "    'send your password',\n",
    "    'send us your account',\n",
    "    'transmit us your account',\n",
    "    'transmit us your account',\n",
    "    'submit us your account',\n",
    "    'send us your account'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ham = [\n",
    "    'Your activity report',\n",
    "    'Your action report',\n",
    "    'Your bodily function report',\n",
    "    'Your activity report',\n",
    "    'benefits physical activity',\n",
    "    'welfare physical activity',\n",
    "    'gains physical activity',\n",
    "    'advantages physical activity',\n",
    "    'benefits physical activity',\n",
    "    'the importance vows',\n",
    "    'the importance vows',\n",
    "    'the importance vows',\n",
    "    'the importance vows',\n",
    "    'the importance vows',\n",
    "    'Your activity report',\n",
    "    'Your action report',\n",
    "    'Your bodily function report',\n",
    "    'Your activity report',\n",
    "    'benefits physical activity',\n",
    "    'gains physical activity'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['renew your password', 'renew your vows', 'benefits of our account', 'the importance of physical activity']\n"
     ]
    }
   ],
   "source": [
    "tests = []\n",
    "for i in new_emails['spam']:\n",
    "    tests.append(i)\n",
    "    \n",
    "for i in new_emails['ham']:\n",
    "    tests.append(i)\n",
    "    \n",
    "print(tests)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['renew', 'your', 'password'], ['renew', 'your', 'vows'], ['benefits', 'of', 'our', 'account'], ['the', 'importance', 'of', 'physical', 'activity']]\n"
     ]
    }
   ],
   "source": [
    "distinct_words_as_sentences_test = []\n",
    "\n",
    "for sentence in tests:\n",
    "    sentence_as_list = sentence.split()\n",
    "    senten = []\n",
    "    for word in sentence_as_list:\n",
    "        senten.append(word)\n",
    "    distinct_words_as_sentences_test.append(senten)\n",
    "        \n",
    "print(distinct_words_as_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['renew', 'your', 'password'], ['renew', 'your', 'vows']]\n",
      "[['benefits', 'of', 'our', 'account'], ['the', 'importance', 'of', 'physical', 'activity']]\n"
     ]
    }
   ],
   "source": [
    "test_spam_tokenized = [distinct_words_as_sentences_test[0], distinct_words_as_sentences_test[1]]\n",
    "test_ham_tokenized = [distinct_words_as_sentences_test[2], distinct_words_as_sentences_test[3]]\n",
    "print(test_spam_tokenized)\n",
    "print(test_ham_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'renew', word not present in labelled spam training data\n",
      "'your', ok\n",
      "'password', ok\n",
      "'renew', word not present in labelled spam training data\n",
      "'your', ok\n",
      "'vows', ok\n",
      "[['your', 'password'], ['your', 'vows']]\n"
     ]
    }
   ],
   "source": [
    "reduced_sentences_spam_test = []\n",
    "for sentence in test_spam_tokenized:\n",
    "    words_ = []\n",
    "    for word in sentence:\n",
    "        if word in vocab_unique_words_spam:\n",
    "            print(f\"'{word}', ok\")\n",
    "            words_.append(word)\n",
    "        elif word in vocab_unique_words_ham:\n",
    "            print(f\"'{word}', ok\")\n",
    "            words_.append(word)\n",
    "        else:\n",
    "            print(f\"'{word}', word not present in labelled spam training data\")\n",
    "    reduced_sentences_spam_test.append(words_)\n",
    "print(reduced_sentences_spam_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'benefits', ok\n",
      "'of', word not present in labelled ham training data\n",
      "'our', ok\n",
      "'account', ok\n",
      "'the', ok\n",
      "'importance', ok\n",
      "'of', word not present in labelled ham training data\n",
      "'physical', ok\n",
      "'activity', ok\n",
      "[['benefits', 'our', 'account'], ['the', 'importance', 'physical', 'activity']]\n"
     ]
    }
   ],
   "source": [
    "reduced_sentences_ham_test = []                   # repeat for ham words\n",
    "for sentence in test_ham_tokenized:\n",
    "    words_ = []\n",
    "    for word in sentence:\n",
    "        if word in vocab_unique_words_ham:\n",
    "            print(f\"'{word}', ok\")\n",
    "            words_.append(word)\n",
    "        elif word in vocab_unique_words_spam:\n",
    "            print(f\"'{word}', ok\")\n",
    "            words_.append(word)\n",
    "        else:\n",
    "            print(f\"'{word}', word not present in labelled ham training data\")\n",
    "    reduced_sentences_ham_test.append(words_)\n",
    "print(reduced_sentences_ham_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove\n",
      "remove\n",
      "[['password'], ['vows']]\n"
     ]
    }
   ],
   "source": [
    "test_spam_stemmed = []\n",
    "non_key = ['us',  'the', 'of','your']       # non-key words, gathered from spam,ham and test sentences\n",
    "for email in reduced_sentences_spam_test:\n",
    "    email_stemmed=[]\n",
    "    for word in email:\n",
    "        if word in non_key:\n",
    "            print('remove')\n",
    "        else:\n",
    "            email_stemmed.append(word)\n",
    "    test_spam_stemmed.append(email_stemmed)\n",
    "            \n",
    "print(test_spam_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove\n",
      "[['benefits', 'our', 'account'], ['importance', 'physical', 'activity']]\n"
     ]
    }
   ],
   "source": [
    "test_ham_stemmed = []\n",
    "non_key = ['us',  'the', 'of', 'your'] \n",
    "for email in reduced_sentences_ham_test:\n",
    "    email_stemmed=[]\n",
    "    for word in email:\n",
    "        if word in non_key:\n",
    "            print('remove')\n",
    "        else:\n",
    "            email_stemmed.append(word)\n",
    "    test_ham_stemmed.append(email_stemmed)\n",
    "            \n",
    "print(test_ham_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(list_) :        # function to multiply all word probs together \n",
    "    total_prob = 1\n",
    "    for i in list_: \n",
    "         total_prob = total_prob * i  \n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           Testing stemmed SPAM email ['password'] :\n",
      "                 Test word by word: \n",
      "prob of spam in general  0.5714285714285714\n",
      "prob \"password\"  is a spam word : 0.5\n",
      "prob of ham in general  0.42857142857142855\n",
      "WH for password is 0.2\n",
      "prob 'password' is a ham word: 0.2\n",
      "\n",
      "Using Bayes, prob the the word 'password' is spam: 0.7692307692307692\n",
      "###########################\n",
      "All word probabilities for this sentence: [0.7692307692307692]\n",
      "email is SPAM: with spammy confidence of 76.92307692307692%\n",
      "0.7692307692307692\n",
      "\n",
      "           Testing stemmed SPAM email ['vows'] :\n",
      "                 Test word by word: \n",
      "prob of spam in general  0.5714285714285714\n",
      "prob 'vows' is a spam word: 0.16666666666666666\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob \"vows\" is a ham word:  0.4\n",
      "\n",
      "Using Bayes, prob the the word 'vows' is spam: 0.35714285714285715\n",
      "###########################\n",
      "All word probabilities for this sentence: [0.35714285714285715]\n",
      "email is HAM: with spammy confidence of 35.714285714285715%\n",
      "0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "def Bayes(email):\n",
    "    probs = []\n",
    "    for word in email:\n",
    "        Pr_S = prob_spam\n",
    "        print('prob of spam in general ',Pr_S)\n",
    "        try:\n",
    "            pr_WS = dict_spamicity[word]\n",
    "            print(f'prob \"{word}\"  is a spam word : {pr_WS}')\n",
    "        except KeyError:\n",
    "            pr_WS = 1/(total_spam+2)  # Apply smoothing for word not seen in spam training data, but seen in ham training \n",
    "            print(f\"prob '{word}' is a spam word: {pr_WS}\")\n",
    "            \n",
    "        Pr_H = prob_ham\n",
    "        print('prob of ham in general ', Pr_H)\n",
    "        try:\n",
    "            pr_WH = dict_hamicity[word]\n",
    "            print(f'prob \"{word}\" is a ham word: ',pr_WH)\n",
    "        except KeyError:\n",
    "            pr_WH = (1/(total_ham+2))  # Apply smoothing for word not seen in ham training data, but seen in spam training\n",
    "            print(f\"WH for {word} is {pr_WH}\")\n",
    "            print(f\"prob '{word}' is a ham word: {pr_WH}\")\n",
    "        \n",
    "        prob_word_is_spam_BAYES = (pr_WS*Pr_S)/((pr_WS*Pr_S)+(pr_WH*Pr_H))\n",
    "        print('')\n",
    "        print(f\"Using Bayes, prob the the word '{word}' is spam: {prob_word_is_spam_BAYES}\")\n",
    "        print('###########################')\n",
    "        probs.append(prob_word_is_spam_BAYES)\n",
    "    print(f\"All word probabilities for this sentence: {probs}\")\n",
    "    final_classification = mult(probs)\n",
    "    if final_classification >= 0.5:\n",
    "        print(f'email is SPAM: with spammy confidence of {final_classification*100}%')\n",
    "    else:\n",
    "        print(f'email is HAM: with spammy confidence of {final_classification*100}%')\n",
    "    return final_classification\n",
    "for email in test_spam_stemmed:\n",
    "    print('')\n",
    "    print(f\"           Testing stemmed SPAM email {email} :\")\n",
    "    print('                 Test word by word: ')\n",
    "    all_word_probs = Bayes(email)\n",
    "    print(all_word_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write you reflection in below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
