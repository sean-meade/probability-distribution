{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Ranganathan Deventhiran"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 23315695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Prior Probabilities:\n",
    "\n",
    "The prior probabilities represent the probability of each class (spam or ham) occurring in the training dataset. \n",
    "To calculate the prior probabilities:\n",
    "- Count the number of emails in the training set that belong to each class.\n",
    "- Divide the count of emails in each class by the total number of emails in the training set\n",
    "\n",
    "piror_spam= count(previous_spam) / (count(previous_spam) + count(previous_ham)) = 4/7 = 0.5714285714285714 <br>\n",
    "prior_ham = count(previous_ham) / (count(previous_spam) + count(previous_ham)) = 3/7 = 0.42857142857142855\n",
    "\n",
    "##  Conditional Probabilities:\n",
    "The conditional probabilities represent the likelihood of each feature given a specific class (spam or ham). <br>\n",
    "To calculate the conditional probabilities:<br>\n",
    "- For each feature, count the occurrences of the each word  in spam emails.\n",
    "- divide it by the total count of all words in spam emails\n",
    "- Laplace Smoothing :\n",
    "<t><t><p>In situations where a feature does not appear in the training set for a particular class, the conditional probability becomes zero, which can lead to issues when calculating posterior probabilities. To mitigate this problem, we add 1 to the counts of all features in both classes and increase the total count of words in the vocabulary by the number of unique words</p>\n",
    "\n",
    "|   word                 |                  probability     |\n",
    "|------------------------|--------------------------------- |              \n",
    "|p(send/SPAM)            |              0.18181818181818182 |           \n",
    "|p(us/SPAM)              |              0.13636363636363635 |          \n",
    "|p(your/SPAM)            |              0.18181818181818182 |          \n",
    "|p(password/SPAM)        |              0.13636363636363635 |          \n",
    "|p(review/SPAM)          |              0.09090909090909091 |          \n",
    "|p(our/SPAM)             |              0.09090909090909091 |          \n",
    "|p(website/SPAM)         |              0.09090909090909091 |          \n",
    "|p(account/SPAM)         |              0.09090909090909091 |\n",
    "|p(your/HAM)             |              0.11764705882352941 |\n",
    "|p(actity/HAM)           |              0.11764705882352941 |\n",
    "|p(report/HAM)           |              0.11764705882352941 |\n",
    "|p(benefits/HAM)         |              0.11764705882352941 |\n",
    "|p(physical/HAM)         |              0.11764705882352941 |\n",
    "|p(the/HAM)              |              0.11764705882352941 |\n",
    "|p(importance/HAM)       |              0.11764705882352941 |\n",
    "|p(vows/HAM)             |              0.11764705882352941 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamOrHamFilter:\n",
    "    \"\"\" \n",
    "       SpamOrHamFilter class is used to filter incoming mail for SPAM or ham using\n",
    "       Naive Bayes Classifier \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.prior_spam = 0.0\n",
    "        self.prior_ham = 0.0\n",
    "        self.spam_word_probs = {}\n",
    "        self.ham_word_probs = {}\n",
    "\n",
    "    def prep_word_count_dict(self,list_of_email):\n",
    "        \"\"\" \n",
    "        this method takes the list of emails and create the work dictionary with each unique word as key and \n",
    "        the occurences of this word in all the email as value\n",
    "        \"\"\"\n",
    "        word_dict={}\n",
    "        total_words=0\n",
    "        for email in list_of_email:\n",
    "            words = email.lower().split() \n",
    "            for word in words:               \n",
    "                word_dict[word] = word_dict.get(word, 0) + 1  \n",
    "                total_words += 1\n",
    "        return total_words,word_dict\n",
    "\n",
    "    def calculate_probabiltiy(self, previous_spam,previous_ham):\n",
    "        \"\"\" \n",
    "        this method takes word dictionaries created by prep_word_count_dict method for both spam and ham email lists\n",
    "        calcualte the prior probabilities and word probabilities\n",
    "        count the occurrences of the each word  in spam emails and divide it by the total count of all words in spam emails\n",
    "        \"\"\"\n",
    "        spam_emails = len(previous_spam)\n",
    "        ham_emails = len(previous_ham)\n",
    "        total_emails = spam_emails + ham_emails\n",
    "\n",
    "        self.prior_spam = spam_emails / total_emails #p(spam)\n",
    "        self.prior_ham = ham_emails / total_emails  #p(ham)\n",
    "\n",
    "      \n",
    "\n",
    "        self.spam_total_words,spam_word_counts_dict = self.prep_word_count_dict(previous_spam)\n",
    "\n",
    "        self.ham_total_words,ham_word_counts_dict = self.prep_word_count_dict(previous_ham)\n",
    "        for word, count in spam_word_counts_dict.items():\n",
    "            #Using Laplace smoothing, we add 1 to the counts of all features in both classes and \n",
    "            #increase the total count of words in the vocabulary by the number of unique words (len(spam_word_counts_dict)).\n",
    "            self.spam_word_probs[word] = (count + 1) / (self.spam_total_words + len(spam_word_counts_dict)) # Laplace smoothing \n",
    "            #self.spam_word_probs[word] = (count + 1) / (spam_total_words + 2) #other smooting \n",
    "            #self.spam_word_probs[word] = (count ) / (self.spam_total_words) # without smooting  \n",
    "      \n",
    "                   \n",
    "\n",
    "        for word, count in ham_word_counts_dict.items():\n",
    "            self.ham_word_probs[word] = (count + 1) / (self.ham_total_words + len(ham_word_counts_dict)) # Laplace smoothing \n",
    "\n",
    "    def is_ham_or_spam(self, email):  \n",
    "        \"\"\" \n",
    "        for the given email, this method calculates the posterior probabilities for both spam and ham\n",
    "        and decides whether this email is spam or ham\n",
    "        \"\"\"      \n",
    "        words = email.lower().split()\n",
    "        spam_score = self.prior_spam\n",
    "        ham_score = self.prior_ham\n",
    "\n",
    "        for word in words:           \n",
    "            spam_prob = self.spam_word_probs.get(word, 1 / (sum(self.spam_word_probs.values()) + len(self.spam_word_probs)))\n",
    "            ham_prob = self.ham_word_probs.get(word, 1 / (sum(self.ham_word_probs.values()) + len(self.ham_word_probs)))\n",
    "            spam_score *= spam_prob\n",
    "            ham_score *= ham_prob   \n",
    "\n",
    "        if spam_score > ham_score:\n",
    "            print(\"{:<38} {:<30} {:<30} {:<15}\".format(email, spam_score, ham_score,\"spam\" ))\n",
    "            return \"spam\"\n",
    "        else:\n",
    "            print(\"{:<38} {:<30} {:<30} {:<15}\".format(email, spam_score, ham_score,\"ham\" ))\n",
    "\n",
    "            return \"ham\"\n",
    "    \n",
    "    def predict(self, new_emails : dict):\n",
    "        \"\"\" \n",
    "        Predict method iterate the new_emails\n",
    "        and checks wether the email is spam or ham and calculate the accurecy of predictions.\n",
    "        \"\"\"   \n",
    "        success = 0\n",
    "        total_emails =0\n",
    "        print(\"{:<38} {:<30} {:<30} {:<15}\".format(\"Email\", \"SpamScore\", \"HamScore\" , \"Classification\"))\n",
    "\n",
    "        keys= list(new_emails.keys())\n",
    "        for key in keys:\n",
    "            list_of_emails=new_emails[key]\n",
    "            for email in list_of_emails:\n",
    "                total_emails += 1\n",
    "                if self.is_ham_or_spam(email) == key:\n",
    "                    success += 1\n",
    "        \n",
    "        print(\"Accurecy of prediction(%) is :\",(success/total_emails) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham Or Spam Predictions:\n",
      "Email                                  SpamScore                      HamScore                       Classification \n",
      "renew your password                    0.0015741833923652105          0.0006224712107065047          spam           \n",
      "renew your vows                        0.0012826679493346158          0.0006590871642774756          spam           \n",
      "benefits of our account                5.8303088606118916e-05         6.91634678562783e-05           ham            \n",
      "the importance of physical activity    9.677193033388733e-06          1.3683470538632712e-05         ham            \n",
      "Accurecy of prediction(%) is : 100.0\n"
     ]
    }
   ],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}\n",
    "\n",
    "spamOrHamFilter=SpamOrHamFilter()\n",
    "spamOrHamFilter.calculate_probabiltiy(previous_spam,previous_ham)\n",
    "print(\"Ham Or Spam Predictions:\")\n",
    "spamOrHamFilter.predict(new_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write you reflection in below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
