{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Ranganathan Deventhiran"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 23315695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "   The Naive Bayes Classifier is a probabilistic machine learning algorithm used for classification tasks. It is based on Bayes' theorem and assumes that the features  used to classify instances are conditionally independent of each other given the class\n",
    "   \n",
    "## Prior Probabilities:\n",
    "\n",
    "The prior probabilities represent the probability of each class (spam or ham) occurring in the training dataset. \n",
    "To calculate the prior probabilities:\n",
    "- Count the number of emails in the training set that belong to each class.\n",
    "- Divide the count of emails in each class by the total number of emails in the training set\n",
    "\n",
    "piror_spam= count(previous_spam) / (count(previous_spam) + count(previous_ham)) = 4/7 = 0.5714285714285714 <br>\n",
    "prior_ham = count(previous_ham) / (count(previous_spam) + count(previous_ham)) = 3/7 = 0.42857142857142855\n",
    "\n",
    "##  Conditional Probabilities:\n",
    "The conditional probabilities represent the likelihood of each feature given a specific class (spam or ham). <br>\n",
    "To calculate the conditional probabilities:<br>\n",
    "- For each feature, count the occurrences of the each word  in spam emails.\n",
    "- divide it by the total count of all words in spam emails\n",
    "- Laplace Smoothing :\n",
    "<t><t><p>In situations where a feature does not appear in the training set for a particular class, the conditional probability becomes zero, which can lead to issues when calculating posterior probabilities. To mitigate this problem, we add 1 to the counts of all features in both classes and increase the total count of words in the vocabulary by the number of unique words</p>\n",
    "\n",
    "|   word                 |Laplace smoo..|      probability     |\n",
    "|------------------------|--------------|--------------------- |              \n",
    "|p(send/SPAM)            |(3+1)/(14 + 8)|  0.18181818181818182 |           \n",
    "|p(us/SPAM)              |(2+1)/(14 + 8)|  0.13636363636363635 |          \n",
    "|p(your/SPAM)            |(3+1)/(14 + 8)|  0.18181818181818182 |          \n",
    "|p(password/SPAM)        |(2+1)/(14 + 8)|  0.13636363636363635 |          \n",
    "|p(review/SPAM)          |(1+1)/(14 + 8)|  0.09090909090909091 |          \n",
    "|p(our/SPAM)             |(1+1)/(14 + 8)|  0.09090909090909091 |          \n",
    "|p(website/SPAM)         |(1+1)/(14 + 8)|  0.09090909090909091 |          \n",
    "|p(account/SPAM)         |(1+1)/(14 + 8)|  0.09090909090909091 |\n",
    "|p(your/HAM)             |(1+1)/(9 + 8) |  0.11764705882352941 |\n",
    "|p(actity/HAM)           |(2+1)/(9 + 8) |  0.11764705882352941 |\n",
    "|p(report/HAM)           |(1+1)/(9 + 8) |  0.11764705882352941 |\n",
    "|p(benefits/HAM)         |(1+1)/(9 + 8) |  0.11764705882352941 |\n",
    "|p(physical/HAM)         |(1+1)/(9 + 8) |  0.11764705882352941 |\n",
    "|p(the/HAM)              |(1+1)/(9 + 8) |  0.11764705882352941 |\n",
    "|p(importance/HAM)       |(1+1)/(9 + 8) |  0.11764705882352941 |\n",
    "|p(vows/HAM)             |(1+1)/(9 + 8) |  0.11764705882352941 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bayes' theorem:\n",
    "\n",
    "Now apply Bayes rule and consider email 'renew your password'\n",
    "\n",
    "how to handle Unseen words in training data?\n",
    "\n",
    "It is calculated by taking the reciprocal of the sum of all conditional probabilities in the spam/ham class plus the number of unique words in the spam/ham class. Taking the reciprocal of this sum ensures that the default probability assigned to unseen words is a small value when compared to the known-word probabilities. It prevents assigning a probability of zero to unseen words, which could lead to incorrect classifications\n",
    "  lets calculate P('renew' | spam) = (1 / (sum of all spam probabilities) + number of unique words)\n",
    "                                   = (1/(1+8))\n",
    "                                   = 0.1111111111111111\n",
    "let's calculate the spam and ham score\n",
    "\n",
    "For spam:<br>\n",
    "        P(spam | 'renew your password') ∝ P(spam) × P('renew' | spam) × P('your' | spam) × P('password' | spam)<br>\n",
    "\n",
    "        ≈ 0.5714285714285714 × 0.1111111111111111 × 0.18181818181818182 × 0.13636363636363635    <br>   \n",
    "\n",
    "        ≈ 0.0015741833923652105 <br>\n",
    "\n",
    "For ham: (There are 2 unseen words renew and password in ham, use above approach)<br>\n",
    "\n",
    "        P(ham | 'renew your password') ∝ P(ham) × P('renew' | ham) × P('your' | ham) × P('password' | ham)<br>\n",
    "\n",
    "        ≈ 0.42857142857142855 × 0.1111111111111111 × 0.11764705882352941 ×0.1111111111111111<br>\n",
    "\n",
    "        ≈ 0.0006224712107065047\n",
    "\n",
    "spam score (0.0015741833923652105) is greater than ham score(0.0006224712107065047)<br>\n",
    "\n",
    "so 'renew your password' is a spam\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamOrHamFilter:\n",
    "    \"\"\" \n",
    "       SpamOrHamFilter class is used to filter incoming mail for SPAM or ham using\n",
    "       Naive Bayes Classifier \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.prior_spam = 0.0\n",
    "        self.prior_ham = 0.0\n",
    "        self.spam_word_probs = {}\n",
    "        self.ham_word_probs = {}\n",
    "\n",
    "    def prep_word_count_dict(self,list_of_email):\n",
    "        \"\"\" \n",
    "        this method takes the list of emails and create the work dictionary with each unique word as key and \n",
    "        the occurences of this word in all the email as value\n",
    "        \"\"\"\n",
    "        word_dict={}\n",
    "        total_words=0\n",
    "        for email in list_of_email:\n",
    "            words = email.lower().split() \n",
    "            for word in words:               \n",
    "                word_dict[word] = word_dict.get(word, 0) + 1  \n",
    "                total_words += 1\n",
    "        return total_words,word_dict\n",
    "\n",
    "    def calculate_probabiltiy(self, previous_spam,previous_ham):\n",
    "        \"\"\" \n",
    "        this method takes word dictionaries created by prep_word_count_dict method for both spam and ham email lists\n",
    "        calcualte the prior probabilities and word probabilities\n",
    "        count the occurrences of the each word  in spam emails and divide it by the total count of all words in spam emails\n",
    "        \"\"\"\n",
    "        spam_emails = len(previous_spam)\n",
    "        ham_emails = len(previous_ham)\n",
    "        total_emails = spam_emails + ham_emails\n",
    "\n",
    "        self.prior_spam = spam_emails / total_emails #p(spam)\n",
    "        self.prior_ham = ham_emails / total_emails  #p(ham)\n",
    "\n",
    "\n",
    "        self.spam_total_words,spam_word_counts_dict = self.prep_word_count_dict(previous_spam)\n",
    "\n",
    "        self.ham_total_words,ham_word_counts_dict = self.prep_word_count_dict(previous_ham)\n",
    "\n",
    "\n",
    "        for word, count in spam_word_counts_dict.items():\n",
    "            #Using Laplace smoothing, we add 1 to the counts of all features in both classes and \n",
    "            #increase the total count of words in the vocabulary by the number of unique words (len(spam_word_counts_dict)).\n",
    "            self.spam_word_probs[word] = (count + 1) / (self.spam_total_words + len(spam_word_counts_dict)) # Laplace smoothing    \n",
    "            \n",
    "\n",
    "        for word, count in ham_word_counts_dict.items():\n",
    "            self.ham_word_probs[word] = (count + 1) / (self.ham_total_words + len(ham_word_counts_dict)) # Laplace smoothing \n",
    "\n",
    "    def is_ham_or_spam(self, email):  \n",
    "        \"\"\" \n",
    "        for the given email, this method calculates the posterior probabilities for both spam and ham\n",
    "        and decides whether this email is spam or ham\n",
    "        \"\"\"      \n",
    "        words = email.lower().split()\n",
    "        spam_score = self.prior_spam\n",
    "        ham_score = self.prior_ham\n",
    "\n",
    "        for word in words:           \n",
    "            #To handle unseen words in training data  (1 / (sum(self.spam_word_probs.values()) + len(self.spam_word_probs)) - \n",
    "            #It is calculated by taking the reciprocal of the sum of all \n",
    "            #conditional probabilities in the spam/ham class plus the number of unique words in the spam/ham class\n",
    "            #Taking the reciprocal of this sum ensures that the default probability assigned to unseen words is a small value \n",
    "            # when compared to the known-word probabilities. \n",
    "            # It prevents assigning a probability of zero to unseen words, which could lead to incorrect classifications\n",
    "            spam_prob = self.spam_word_probs.get(word, 1 / (sum(self.spam_word_probs.values()) + len(self.spam_word_probs)))\n",
    "            ham_prob = self.ham_word_probs.get(word, 1 / (sum(self.ham_word_probs.values()) + len(self.ham_word_probs)))\n",
    "            spam_score *= spam_prob\n",
    "            ham_score *= ham_prob   \n",
    "\n",
    "        if spam_score > ham_score:\n",
    "            print(\"{:<38} {:<30} {:<30} {:<15}\".format(email, spam_score, ham_score,\"spam\" ))\n",
    "            return \"spam\"\n",
    "        else:\n",
    "            print(\"{:<38} {:<30} {:<30} {:<15}\".format(email, spam_score, ham_score,\"ham\" ))\n",
    "\n",
    "            return \"ham\"\n",
    "    \n",
    "    def predict(self, new_emails : dict):\n",
    "        \"\"\" \n",
    "        Predict method iterate the new_emails\n",
    "        and checks wether the email is spam or ham and calculate the accurecy of predictions.\n",
    "        \"\"\"   \n",
    "        success = 0\n",
    "        total_emails =0\n",
    "        print(\"{:<38} {:<30} {:<30} {:<15}\".format(\"Email\", \"SpamScore\", \"HamScore\" , \"Classification\"))\n",
    "\n",
    "        keys= list(new_emails.keys())\n",
    "        for key in keys:\n",
    "            list_of_emails=new_emails[key]\n",
    "            for email in list_of_emails:\n",
    "                total_emails += 1\n",
    "                if self.is_ham_or_spam(email) == key:\n",
    "                    success += 1\n",
    "        \n",
    "        print(\"Accurecy of prediction(%) is :\",(success/total_emails) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham Or Spam Predictions:\n",
      "Email                                  SpamScore                      HamScore                       Classification \n",
      "renew your password                    0.0015741833923652105          0.0006224712107065047          spam           \n",
      "renew your vows                        0.0012826679493346158          0.0006590871642774756          spam           \n",
      "benefits of our account                5.8303088606118916e-05         6.91634678562783e-05           ham            \n",
      "the importance of physical activity    9.677193033388733e-06          1.3683470538632712e-05         ham            \n",
      "Accurecy of prediction(%) is : 100.0\n"
     ]
    }
   ],
   "source": [
    "#Testing \n",
    "\n",
    "spamOrHamFilter=SpamOrHamFilter()\n",
    "spamOrHamFilter.calculate_probabiltiy(previous_spam,previous_ham)\n",
    "print(\"Ham Or Spam Predictions:\")\n",
    "spamOrHamFilter.predict(new_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write you reflection in below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
