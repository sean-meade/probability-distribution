{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Sean Meade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 10128921"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you believe required imports are missing, please contact your moderator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below information to create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I created a function for making a list of the words from the string that represents an email. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_words_from_email(email):\n",
    "\n",
    "    \"\"\"\n",
    "    Takes in a string email and produces the words of that email as a list of strings.\n",
    "    \"\"\"\n",
    "\n",
    "    # split the email into a list of words\n",
    "    words = email.split()\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a function that takes in a list of emails and counts the words in it. This is used to find the number of words in the test data for the given spam or ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_count_words_in_emails(words, emails):\n",
    "\n",
    "    \"\"\"\n",
    "    Takes in a list or set of words and checks how many words are in the list of emails.\n",
    "    \"\"\"\n",
    "\n",
    "    words_count = {}\n",
    "\n",
    "    # for every word in our training data\n",
    "    for word in words:\n",
    "        # Create an entry in the dictionary\n",
    "        words_count[word.lower()] = 0\n",
    "        # Then loop through the emails\n",
    "        for email in emails:\n",
    "            # if the word is in the email\n",
    "            if word.lower() in email:\n",
    "                # add the word count to its corresponding dictionary entry\n",
    "                words_count[word.lower()] += email.count(word)\n",
    "    \n",
    "    return words_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I use the output of the last function to calculate the probability the email is in that category.\n",
    "\n",
    "$$ \\mathbb{P}(word|S) = \\frac{number~of~spam~emails~containing~the~word~+~1}{number~of~spam~emails~+~2} $$\n",
    "\n",
    "$$ \\mathbb{P}(word|H) = \\frac{number~of~ham~emails~containing~the~word~+~1}{number~of~ham~emails~+~2} $$\n",
    "\n",
    "I use Laplace smoothing to account for words in the test emails that are not in the training emails. This is done by adding 1 to the numerator and 2 to the denominator. So instead of an untrained words working out to a probability of zero it will work out at 1 over the number of emails in that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_word_in_emails(word_count, emails):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the probability of each word given the email is spam or ham.\n",
    "    \"\"\"\n",
    "\n",
    "    # a dictionary that will contain the probabilities for each word for a given category\n",
    "    word_prob = {}\n",
    "    # number of emails\n",
    "    email_count = len(emails)\n",
    "    # using the word and it's count\n",
    "    for word, count in word_count.items():\n",
    "        # calculate the probability that the word is spam or hame\n",
    "        word_prob[word] = (count + 1)/(email_count + 2)\n",
    "    \n",
    "    return word_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then work out the probability of an email being spam or ham based on the training data.\n",
    "\n",
    "$$ \\mathbb{P}(S) = \\frac{number~of~spam~emails}{total~number~of~emails} $$\n",
    "$$ \\mathbb{P}(H) = \\frac{number~of~ham~emails}{total~number~of~emails} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_spam_and_ham(spam_emails, ham_emails):\n",
    "    \"\"\"\n",
    "    This function takes the spam and ham emails and returns the probability that an email will be ham or spam based on that\n",
    "    \"\"\"\n",
    "\n",
    "    # a dictionary to hold the returned probabilities\n",
    "    probs = {}\n",
    "\n",
    "    # total number of emails\n",
    "    total_email_count = len(spam_emails) + len(ham_emails)\n",
    "\n",
    "    # then work out the probabilities by the number of emails in the category divided by the total number of emails \n",
    "    probs[\"prob_email_spam\"] = len(spam_emails)/total_email_count\n",
    "    probs[\"prob_email_ham\"] = len(ham_emails)/total_email_count\n",
    "\n",
    "    return probs\n",
    "\n",
    "# Calculate and save the probability an email is spam and ham\n",
    "prob_of_spam_and_ham = probability_of_spam_and_ham(previous_spam, previous_ham)\n",
    "P_S = prob_of_spam_and_ham[\"prob_email_spam\"]\n",
    "P_H = prob_of_spam_and_ham[\"prob_email_ham\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as expected the probability of an email being spam plus the probability of an email being ham is equal to 1, because they are the only two possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_S + P_H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next one uses the list_of_words_from_email function on a list of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_words_from_emails(emails):\n",
    "    \"\"\"\n",
    "    takes in a list of strings representing emails and returns a list of all the words\n",
    "    \"\"\"\n",
    "\n",
    "    # a list to contain the returned list of words\n",
    "    words_in_emails = []\n",
    "\n",
    "    # loop through emails\n",
    "    for email in emails:\n",
    "        # split the email into words and add them to returned list\n",
    "        words_in_emails += list_of_words_from_email(email)\n",
    "\n",
    "    return words_in_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then tying it all together into one function that returns the probability of each word for that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_words_for(emails):\n",
    "    \"\"\"\n",
    "    Takes in a list of emails (either ham or spam) and returns the probability of \n",
    "    each word given the email was spam or ham.\n",
    "    \"\"\"\n",
    "\n",
    "    words = list_of_words_from_emails(emails)\n",
    "    word_count = dict_count_words_in_emails(words, emails)\n",
    "    word_probs = prob_of_word_in_emails(word_count, emails)\n",
    "\n",
    "    return word_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we tie everything together we can work out the probability an email is spam given the words on the email:\n",
    "\n",
    "$$ \\mathbb{P}(S|x_1,...,x_i) \\approx \\frac{\\mathbb{P}(S)\\prod_{i=1}^{n}\\mathbb{P}(x_i|S)}{\\mathbb{P}(S)\\prod_{i=1}^{n}\\mathbb{P}(x_i|S)~+~\\mathbb{P}(H)\\prod_{i=1}^{n}\\mathbb{P}(x_i|H)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spam': {'renew your password': [True, 0.9174311926605504],\n",
       "  'renew your vows': [True, 0.6493506493506493]},\n",
       " 'ham': {'benefits of our account': [True, 0.7941550190597204],\n",
       "  'the importance of physical activity': [False, 0.026092764998121312]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prob_of_email_being_spam(previous_spam, previous_ham, test_emails, threshold=0.6):\n",
    "\n",
    "    \"\"\"\n",
    "    A function that takes in a list of test emails for spam (previous_spam) and ham (previous_ham), a dictionary containing spam and ham emails (test_emails), and an optional float number for the probability threshold (threshold).\n",
    "    \"\"\"\n",
    "\n",
    "    # the two categories\n",
    "    categories = [\"spam\", \"ham\"]\n",
    "\n",
    "    # the output dictionary that holds the emails, the calculated probability, and the boolean of whether the function classes it as spam or not\n",
    "    email_is_spam = {\"spam\": {}, \"ham\": {}}\n",
    "\n",
    "    # all unique words in the training data\n",
    "    training_words = set(list_of_words_from_emails(previous_ham) + list_of_words_from_emails(previous_spam))\n",
    "\n",
    "    # the probability an email could be spam or ham\n",
    "    prob_of_spam_and_ham = probability_of_spam_and_ham(previous_spam, previous_ham)\n",
    "    P_S = prob_of_spam_and_ham[\"prob_email_spam\"]\n",
    "    P_H = prob_of_spam_and_ham[\"prob_email_ham\"]\n",
    "\n",
    "    # Dictionaries of the probability of each word given the category\n",
    "    P_w_S = prob_of_words_for(previous_spam)\n",
    "    P_w_H = prob_of_words_for(previous_ham)\n",
    "\n",
    "    # for each category\n",
    "    for cat in categories:\n",
    "        # and for each email in the test data for that category\n",
    "        for email in test_emails[cat]:\n",
    "            # get the unique words in the email\n",
    "            words_in_email = set(list_of_words_from_email(email))\n",
    "            # set new variables to hold the product of all the probabilities of each word given its spam or ham\n",
    "            P_wi_S = P_S\n",
    "            P_wi_H = P_H\n",
    "            # for each word in the email\n",
    "            for word in words_in_email:\n",
    "                # and if that word is in the training data\n",
    "                if word in training_words:\n",
    "                    # check to see its in the spam data\n",
    "                    try:\n",
    "                        # and multiply it in\n",
    "                        P_wi_S *= P_w_S[word]\n",
    "                    except:\n",
    "                        # otherwise use the laplace to add the probability so it doesn't multiply to zero\n",
    "                        P_wi_S *= 1/(2 + len(previous_spam))\n",
    "                    # check to see its in the ham data\n",
    "                    try:\n",
    "                        # and multiply it in\n",
    "                        P_wi_H *= P_w_H[word]\n",
    "                    except:\n",
    "                        # otherwise use the laplace to add the probability so it doesn't multiply to zero\n",
    "                        P_wi_H *= 1/(2 + len(previous_ham))\n",
    "            # work out the probability that the email is spam\n",
    "            probability_its_spam = P_wi_S/(P_wi_S + P_wi_H)\n",
    "            # add the email to the output\n",
    "            email_is_spam[cat][email] = [(probability_its_spam > threshold), probability_its_spam]\n",
    "\n",
    "    return email_is_spam\n",
    "\n",
    "# run the function with the data given\n",
    "prob_of_email_being_spam(previous_spam, previous_ham, new_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last output shows whether the spam filter categorizes it as spam or not and the probability calculated for it. You will notice that the spam emails and the second ham email are predicted correctly. However if the filter is set to anything less 0.79 then this email will be classed as spam even though it's classed as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send us your password',\n",
       " 'review our website',\n",
       " 'send your password',\n",
       " 'send us your account']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'benefits of our account' has two words ('account' and 'our) in the spam training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Your activity report', 'benefits physical activity', 'the importance vows']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'benefits of our account' only has one word ('benefits') in the ham training data.\n",
    "\n",
    "This has thrown off the calculation. To fix this using more data would probably even things out a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Jason Colemans comment on my forum post and going through the code a second time I realized that the remove_untrained_words function was not needed. This led to reducing my code and still functioning correctly.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
