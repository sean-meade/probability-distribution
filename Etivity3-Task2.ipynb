{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook E-tivity 3 CE4021 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Peter O'Mahony"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: 8361967"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Markdown cell with problem description - Remember to merge these into one)_\n",
    "## Problem Description\n",
    "Create a Naive Bayes SPAM filter. Test your filter using the messages in new_emails. You may add as many cells as you require to complete the task.\n",
    "\n",
    "\n",
    "## Initial Thoughts\n",
    "There will be an initial training task and then an analysis of new emails.  I guess we create a dictionary of words in the spam and another of ham words. Does the context or position matter? Is our software supposed to understand the difference between our and your in terms of ownership or are we simply looking at word frequency?\n",
    "\n",
    "## Later Thoughts\n",
    "Is this a question of simply taking each word in an email and summing the frequency of that word in spam (and using the negative amount) and ham (using the positive amount) and if the result is not less than zero, we conclude that it is ham? Seems too basic and not using enough theory.\n",
    "\n",
    "Is there a clear definition of what a Naive Bayes Spam Filter actually is? Does it just score a block of text based on proportion of spamwords versus hamwords?  I'll sleep on it after a Friday pint.\n",
    "\n",
    "...OK I had the pint and now I'm thinking that I need a function to calculate the probability of a word indicating that the message is spam. If that works, then I should do it for every word in the email and multiply those probabilities together to score the whole email.\n",
    "\n",
    "I'm very curious to see how much better that algorithm will be than the intuitive one I started with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "We are exploring the application of Bayes Rule so let's be clear on what that is.  It looks like this:\n",
    "\n",
    "$$ P(H|E)^\\color{green}{\\text{\"posterior\"}} = P(H)^\\color{green}{\\text{\"prior\"}}  \\frac{P(E|H)^\\color{green}{\\text{\"likelihood\"}} }{P(E)^\\color{green}{\\text{\"marginal\"}}} $$\n",
    "\n",
    "where H represents the Hypothesis and E is the Evidence.  The real challenge (for me at least) is that of re-stating a task correctly in these terms.\n",
    "\n",
    "In English we can articulate his Rule as giving us the probability of the hypothesis being true, if the evidence is present.  This can also be called the Posterior and it is impolite to look further into this.\n",
    "\n",
    "Can we say H is \"this email is spam\" and E is \"this word is spam\"? Let's try...\n",
    "\n",
    "We'll rewrite it as:\n",
    "$$ P(S|W) = P(S)  \\frac{P(W|S)}{P(W)} $$\n",
    "\n",
    "Looking at \"Notes on Naive Bayes Classifiers for Spam Filtering\" by Jonathan Lee, he expands this more usefully as:\n",
    "$$ P(S|W) = P(S)  \\frac{P(W|S)}{P(W|S)P(S) + P(W|not S)P(not S)} $$\n",
    "\n",
    "\n",
    "In our case the Posterior is the probability that an email is spam.\n",
    "\n",
    "The Prior is the probability of the Hypothesis being true, that is, of an email being spam.\n",
    "\n",
    "The Likelihood is the probability of the email being spam given the Evidence that the word is spammy.\n",
    "\n",
    "The Marginal is the probability that the word is spammy and it has been expanded from P(W) into useful components that say\" the probability of the word appearing in a spam message times the probability of the email being spam plus the probability of the word appearing in a ham message times the probability of the email being ham\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work it out by hand for the message 'benefits of our account'.  After some visual analysis, we can make this reference table:\n",
    "\n",
    "| |Ham|Spam|Total|\n",
    "|-|---|----|------|\n",
    "| all messages | 3 | 4 | 7 |\n",
    "| msgs with 'benefits' | 1 | 0 | 1|\n",
    "| msgs with 'of' | 0 | 0 | 0|\n",
    "| msgs with 'our' | 0 | 1 | 1|\n",
    "| msgs with 'account' | 1 | 3 | 4 |\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(H), the Prior, is the probability that an email is spam and we calculate this as 4/7 because 4 out of our 7 emails are spam.\n",
    "\n",
    "P(E|H), the Likelihood, is the probability that the word is spam given that the email is spam and we calculate this for 'benefits' as 0 because it never appears in any spam emails.\n",
    "\n",
    "P(E), the Marginal, is the probability that the word occuring in an email and that is 1/7. _(But how do we handle words that don't appear in any email? That would give us a divide by zero error!)_\n",
    "\n",
    "so we get\n",
    "$$ P(H|E) = \\frac {4}{7} * \\frac {0}{\\frac {1}{7}} = 0 $$\n",
    "\n",
    "\n",
    "and this tells us that there is 0% chance that this word indicates the email is spam.\n",
    "\n",
    "I say this with 60% certainty so I need to recheck this later.\n",
    "\n",
    "For the next word, 'of', we get the same:\n",
    "$$ P(H|E) = \\frac {4}{7} * \\frac {0}{0^{*}} = 0 $$  $^{*}$ _how can this be?_\n",
    "\n",
    "For the next word, 'our', we get:\n",
    "$$ P(H|E) = \\frac {4}{7} * \\frac {1}{1} = \\frac {4}{7}$$\n",
    "\n",
    "For the last word, 'account', we get:\n",
    "$$ P(H|E) = \\frac {4}{7} * \\frac {1}{\\frac {4}{7}} = 1$$\n",
    "\n",
    "Intuitively, I think that if we multiply P(H|E) for each word in an email then we get the probability that that email is spam but that makes no sense if we can get a zero probability for any word.  We can't add together the probabilities because that could result in a number greater than 1 (using my current calculations as least).\n",
    "\n",
    "Clearly more work is needed here. My maths are wrong right now. No pint for me tonight.\n",
    "\n",
    "Ah, I have now discovered Laplace Smoothing and that might address my zero denominator concern. More to be done here after I absorb the mandatory reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on Initial Implementation\n",
    "I wrote most of the code below before learning about Bayes Rule.  It is based on intuition and I thought that I would find it closely aligned with Bayes but it appears not.  The code tries to identify spam simply based on the spamminess and hamminess of each word in the email. I am leaving it here because I am curious to compare it to the Bayesian results.  If I have time, I will find a much larger dataset and apply both algorithms and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "previous_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "new_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sorted_dict(phrases: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Count the frequency of each word in each phrase on the list and return a dictionary of\n",
    "    words sorted by descending frequency.\n",
    "    \"\"\"\n",
    "    ordered_words = {}\n",
    "    for phrase in phrases:\n",
    "        # assume the phrases have no punctuation and words are delimited by spaces only. Force lowercase for consistency.\n",
    "        words = phrase.lower().split(' ')  \n",
    "        for word in words:\n",
    "            if (word in ordered_words):    # if we know the word already\n",
    "                ordered_words[word] += 1\n",
    "            else:                          # otherwise this is a new word\n",
    "                ordered_words[word] = 1\n",
    "\n",
    "    # sort the words in descending order of frequency\n",
    "    return (dict(sorted(ordered_words.items(), key=lambda item: item[1], reverse=True)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_freq(word: str, built_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    Return the frequency of a word from the dictonary or zero if not found.\n",
    "    \"\"\"\n",
    "    return built_dict[word] if (word in built_dict) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_phrase(phrase: str, built_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    Given a string of words, look up each word in the dictionary.  If found, sum the frequency value\n",
    "    from the dictionary of that word and return the total value/score for all words in the string.\n",
    "    \"\"\"\n",
    "    words = phrase.lower().split(' ')  # split into words and convert to lowercase for consistency\n",
    "    freq = 0\n",
    "    for word in words:\n",
    "        if (word in built_dict):\n",
    "            freq += get_word_freq(word, built_dict)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superscript(power: int) -> str:\n",
    "    \"\"\"\n",
    "    I knew it would come in handy again.\n",
    "    \"\"\"\n",
    "    # created a translation table using https://symbl.cc/en/unicode/blocks/latin-1-supplement/\n",
    "    translate_table = str.maketrans(\"0123456789-.\", \n",
    "                                    \"\\u2070\\u00B9\\u00B2\\u00B3\\u2074\\u2075\\u2076\\u2077\\u2078\\u2079\\u207B\\u00B7\")\n",
    "    return str(power).translate(translate_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_phrase(phrase: str, ham_dict: dict, spam_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    This returns a colour encoded string highlighting the spam and ham \n",
    "    words with an indicator of the frequency of that word in the relevant dictionary.\n",
    "    More of my messing with python.  It is not very efficient but, hey, I had fun writing it.\n",
    "    \"\"\"\n",
    "    red     = '\\x1b[1;31m'\n",
    "    green   = '\\x1b[1;32m'\n",
    "    off     = '\\x1b[0m'\n",
    "    spam    = red\n",
    "    ham     = green\n",
    "    neutral = ''\n",
    "    \n",
    "    pretty_phrase = ''\n",
    "    for word in phrase.split(' '):\n",
    "        ham_score  = get_word_freq(word, ham_dict)\n",
    "        spam_score = get_word_freq(word, spam_dict)\n",
    "        if (ham_score==0) and (spam_score==0):\n",
    "            colour = neutral\n",
    "        else:\n",
    "            if (ham_score>spam_score):\n",
    "                colour = ham\n",
    "                word += superscript(ham_score-spam_score)\n",
    "            else:\n",
    "                colour = spam\n",
    "                word += superscript(spam_score-ham_score)\n",
    "        pretty_phrase += f\"{colour}{word}{off} \"\n",
    "    return pretty_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_or_ham(phrase: str, ham_dict: dict, spam_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    Given a string of words, calculate the ham score and subtract the spam score and \n",
    "    return a string explaining the result.\n",
    "    \"\"\"\n",
    "    score = test_phrase(phrase,ham_dict) - test_phrase(phrase,spam_dict)\n",
    "    result_text = f'Score is {score:3} so '\n",
    "    result_text += 'Spam' if score < 0 else 'Ham '\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pretty_result(phrase: str, ham_dict: dict, spam_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Display the result of our analysis, the score and a colour coded version of the email \n",
    "    indicating the words and weights that influenced the analysis.\n",
    "    \"\"\"\n",
    "    print(f'{spam_or_ham(phrase, ham_dict, spam_dict)}: {colour_phrase(phrase, ham_dict, spam_dict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_emails(new_emails: list, ham_dict: dict, spam_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Given a dictionary keyed by an expected result (spam or ham) with a collection of associated emails,\n",
    "    test each email with the spam_or_ham function to determine its quality.\n",
    "    \"\"\"\n",
    "    for expected_result, emails in new_emails.items():\n",
    "        print(f'\\n---- EXPECTING {expected_result}')\n",
    "        for email in emails:\n",
    "            print_pretty_result(email, ham_dict, spam_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM WORDS (8): {'send': 3, 'your': 3, 'us': 2, 'password': 2, 'review': 1, 'our': 1, 'website': 1, 'account': 1}\n",
      "MEATY HAM WORDS (8): {'activity': 2, 'your': 1, 'report': 1, 'benefits': 1, 'physical': 1, 'the': 1, 'importance': 1, 'vows': 1}\n",
      "\n",
      "==================== REQUIRED TESTS\n",
      "\n",
      "---- EXPECTING spam\n",
      "Score is  -4 so Spam: renew\u001b[0m \u001b[1;31myour²\u001b[0m \u001b[1;31mpassword²\u001b[0m \n",
      "Score is  -1 so Spam: renew\u001b[0m \u001b[1;31myour²\u001b[0m \u001b[1;32mvows¹\u001b[0m \n",
      "\n",
      "---- EXPECTING ham\n",
      "Score is  -1 so Spam: \u001b[1;32mbenefits¹\u001b[0m of\u001b[0m \u001b[1;31mour¹\u001b[0m \u001b[1;31maccount¹\u001b[0m \n",
      "Score is   5 so Ham : \u001b[1;32mthe¹\u001b[0m \u001b[1;32mimportance¹\u001b[0m of\u001b[0m \u001b[1;32mphysical¹\u001b[0m \u001b[1;32mactivity²\u001b[0m \n",
      "\n",
      "==================== OTHER TESTS\n",
      "\n",
      "---- EXPECTING spam\n",
      "Score is  -2 so Spam: get\u001b[0m \u001b[1;31myour²\u001b[0m drugs\u001b[0m here\u001b[0m \n",
      "Score is   0 so Ham : buy\u001b[0m some\u001b[0m viagra\u001b[0m from\u001b[0m this\u001b[0m super\u001b[0m web\u001b[0m site\u001b[0m \n",
      "\n",
      "---- EXPECTING ham\n",
      "Score is  -1 so Spam: \u001b[1;31msend³\u001b[0m \u001b[1;31mus²\u001b[0m \u001b[1;32mthe¹\u001b[0m \u001b[1;32mphysical¹\u001b[0m \u001b[1;32mbenefits¹\u001b[0m of\u001b[0m important\u001b[0m \u001b[1;31maccount¹\u001b[0m \u001b[1;32mactivity²\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "# Train/Build the Spam dictionary\n",
    "spam_dict = build_sorted_dict(previous_spam)\n",
    "print(f'SPAM WORDS ({len(spam_dict)}):',spam_dict)\n",
    "# Train/Build the Ham dictionary\n",
    "ham_dict = build_sorted_dict(previous_ham)\n",
    "print(f'MEATY HAM WORDS ({len(ham_dict)}):',ham_dict)\n",
    "# Test all new emails and praise or condemn them\n",
    "print(f'\\n==================== REQUIRED TESTS')\n",
    "process_new_emails(new_emails, ham_dict, spam_dict)\n",
    "\n",
    "print(f'\\n==================== OTHER TESTS')\n",
    "my_emails = {\n",
    "    \"spam\":[\n",
    "        \"get your drugs here\",\n",
    "        \"buy some viagra from this super web site\"\n",
    "        ],\n",
    "    \"ham\":[\n",
    "        \"send us the physical benefits of important account activity\"\n",
    "        ]\n",
    "    }\n",
    "process_new_emails(my_emails, ham_dict, spam_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts\n",
    "We correctly identified both spam messages as spam (100% true positives) but incorrectly classified one ham message as spam (50% false positive).\n",
    "\n",
    "I guess we start to apply the probability and Naive Bayes story here. To be done..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\\\"border:2px solid gray\\\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
